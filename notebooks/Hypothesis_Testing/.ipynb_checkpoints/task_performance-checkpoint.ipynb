{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e348dead",
   "metadata": {},
   "source": [
    "# Task Performance Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7139f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_rw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-52fd6a0c774b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_rw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_rw' is not defined"
     ]
    }
   ],
   "source": [
    "df_rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cba6fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b7cb1b03ef8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load necessary libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshapiro\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\testing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m from pandas._testing import (\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pandas\\_testing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m \u001b[0mcython_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"task_performance.csv\"  # Replace with actual file path\n",
    "df_task_performance = pd.read_csv(file_path)\n",
    "\n",
    "# Filter only real-world (RW) trials\n",
    "df_rw = df_task_performance.filter(regex=\"^PERSONAL|^RW\")\n",
    "\n",
    "# Melt the dataset to long format\n",
    "df_long = df_rw.melt(id_vars=[\"PERSONAL_Controller being tested?\", \"PERSONAL_participant_code\"], \n",
    "                      var_name=\"Task\", value_name=\"Score\")\n",
    "\n",
    "# Extract Modality, Trial Number, and Subtask from column names\n",
    "df_long[\"Modality\"] = df_long[\"Task\"].apply(lambda x: \"WITH-VR\" if \"WITH-VR\" in x else \"NO-VR\")\n",
    "df_long[\"Trial\"] = df_long[\"Task\"].str.extract(r\"TASK (\\d)\").astype(int)\n",
    "df_long[\"Subtask\"] = df_long[\"Task\"].str.extract(r\"\\[([^\\]]+)\\]\")  # Extract subtask names\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_long.rename(columns={\"PERSONAL_Controller being tested?\": \"Controller\",\n",
    "                        \"PERSONAL_participant_code\": \"Participant\"}, inplace=True)\n",
    "\n",
    "# Drop the original \"Task\" column as it has been split into meaningful components\n",
    "df_long.drop(columns=[\"Task\"], inplace=True)\n",
    "\n",
    "# Check normality using Shapiro-Wilk test\n",
    "shapiro_test = shapiro(df_long[\"Score\"])\n",
    "\n",
    "# Fit the Linear Mixed-Effects Model (LMM)\n",
    "lmm_model_performance = smf.mixedlm(\n",
    "    \"Score ~ Controller * Modality * Trial * Subtask\", \n",
    "    df_long, \n",
    "    groups=df_long[\"Participant\"]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lmm_result_performance = lmm_model_performance.fit()\n",
    "\n",
    "# Display results\n",
    "print(\"Shapiro-Wilk Test for Normality:\")\n",
    "print(f\"Statistic={shapiro_test.statistic}, p-value={shapiro_test.pvalue}\\n\")\n",
    "\n",
    "print(\"Linear Mixed-Effects Model Results:\")\n",
    "print(lmm_result_performance.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd79d26",
   "metadata": {},
   "source": [
    "To analyze task performance across tasks and trials, a LMM was applied to account for repeated measures while considering Controller, Modality, Trial Number, and Task as fixed effects. LMM allows for a robust analysis of within-subject variability while handling potential missing values without the need for pairwise deletion. A Shapiro-Wilk test confirmed that task scores were not normally distributed (p < 0.05), supporting the use of LMM over traditional parametric methods such as ANOVA.\n",
    "\n",
    "The model revealed that baseline performance was high, with an average task score of 9.40/10 (p < 0.0001). The controller type did not significantly influence task performance, as WBC had a slightly lower average score (-1.50 points, p = 0.268), but this difference was not statistically significant. Similarly, the visualization modality did not have a strong impact, with WITH-VR resulting in a small performance decrease (-1.20 points, p = 0.371), but again, this was not significant. Performance remained stable across trials, with no notable learning or fatigue effects (p = 1.000), and there was no significant variation across different tasks, meaning no single task was consistently harder or easier than the others. Additionally, no significant interaction effects between Controller, Modality, Trial, and Task were observed (p > 0.05), suggesting that task performance differences were stable across all conditions and trials.\n",
    "\n",
    "These results suggest that task performance was consistent across different controllers, modalities, and trials, with no strong evidence that WITH-VR or WBC hindered performance. Participants consistently scored above 9 on average, demonstrating a high level of task execution accuracy across all conditions. Unlike the completion time analysis, where WITH-VR significantly increased task duration, here we see that performance scores remained unaffected by visualization modality, implying that while VR may slow down execution, it does not necessarily lead to task failure or lower performance quality. Similarly, controller type did not significantly impact task scores, meaning both SBC and WBC were equally effective in executing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb71230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
